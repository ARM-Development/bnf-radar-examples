{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2637142-0fde-46c9-b5c3-4c5c4e5fef80",
   "metadata": {},
   "source": [
    "<img src=\"images/arm_logo.png\" width=500 alt=\"ARM Logo\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f0bb8e-facf-4d8d-bf47-ba813d6b6d09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bankhead National Forest - RadClss Example\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Extracted Radar Columns and In-Situ Sensors (RadClss) Value-Added Product (VAP) is\n",
    "a dataset containing in-situ ground observations matched to CSAPR-2 radar columns above ARM Mobile Facility (AMF-3) supplemental sites of interest. \n",
    "\n",
    "RadCLss is intended to provide a dataset for algorthim development and validation of precipitation retrievals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4f954-2b6a-436c-ab90-d2905dc6e69c",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro to Cartopy](https://foundations.projectpythia.org/core/cartopy/cartopy.html) | Necessary | |\n",
    "| [Understanding of NetCDF](https://foundations.projectpythia.org/core/data-formats/netcdf-cf.html) | Helpful | Familiarity with metadata structure |\n",
    "| [GeoPandas](https://geopandas.org/en/stable/docs.html) | Necessary | Familiarity with Geospatial Plotting|\n",
    "| [Py-ART / Radar Foundations](https://projectpythia.org/radar-cookbook/README.html) | Necessary | Basics of Weather Radar | \n",
    "\n",
    "- **Time to learn**: 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099ee1f-4dca-4b19-8192-0ecef80df30a",
   "metadata": {},
   "source": [
    "## Current List of Supported Sites of Interest\n",
    "| Site  | Lat   | Lon   |\n",
    "| ----- | ----- | ----- |\n",
    "| M1    | 34.34525 | -87.33842 |\n",
    "| S4    | 34.46451 | -87.23598 |\n",
    "| S20   | 34.65401 | -87.29264 |\n",
    "| S30   | 34.38501 | -86.92757 |\n",
    "| S40   | 34.17932 | -87.45349 |\n",
    "| S10   | 34.343611 | -87.350278 |\n",
    "\n",
    "## Pending List of Supported Sites of Interest\n",
    "| Site  | Lat   | Lon   |\n",
    "| ----- | ----- | ----- |\n",
    "| S13    | 34.343889 | -87.350556 |\n",
    "| S14    | 34.343333 | -87.350833 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1626c58-6fda-42b9-bbf3-1dbdd4b81f5e",
   "metadata": {},
   "source": [
    "<img src=\"images/bnf-in-situ-locations.png\" width=1500 alt=\"BNF Sensors\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2465bc-4681-489e-ac79-ee8330c94dd0",
   "metadata": {},
   "source": [
    "## Current List of Supported In-Situ Ground Observations\n",
    "- Surface Meteorological Instrumentation [MET] (DOI: 10.5439/1786358)\n",
    "    - M1, S20, S30, S40\n",
    "- Balloon-borne sounding system [SONDEWNPN] (DOI: 10.5439/1595321)\n",
    "    - M1\n",
    "- Pluvio Weighing Bucket Precipitation Gauge [WBPLUVIO2] (DOI: 10.5439/1338194)\n",
    "    - M1\n",
    "- Laser Disdrometer [LD] (DOI: 10.5439/1432694)\n",
    "    - M1, S30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ab264-3cec-4824-b8ee-712c2e7a664c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import dask\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from math import atan2 as atan2\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "from cartopy.io.img_tiles import OSM\n",
    "from matplotlib.transforms import offset_copy\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from metpy.plots import USCOUNTIES\n",
    "\n",
    "import act\n",
    "import pyart\n",
    "\n",
    "dask.config.set({'logging.distributed': 'error'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa066eb",
   "metadata": {},
   "source": [
    "## Define Processing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired processing date for the BNF CSAPR-2 in YYYY-MM-DD format.\n",
    "DATE = \"2025-05-24\"\n",
    "# Define the directory where the BNF CSAPR-2 CMAC files are located.\n",
    "RADAR_DIR = \"/nfs/gce/globalscratch/obrienj/bnf-cmac-r4/202505/\"\n",
    "# Define an output directory for downloaded ground instrumentation\n",
    "INSITU_DIR = \"/nfs/gce/globalscratch/obrienj/bnf-cmac-r4/in_situ/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ARM Username and ARM Token with ARM Live service for downloading ground instrumentation via ACT.DISCOVERY\n",
    "# With your ARM username, you can find your ARM Live token here: https://adc.arm.gov/armlive/\n",
    "##ARM_USERNAME = os.getenv(\"ARM_USERNAME\")\n",
    "##ARM_TOKEN = os.getenv(\"ARM_TOKEN\")\n",
    "ARM_USERNAME = \"jrobrien\"\n",
    "ARM_TOKEN = \"5c339110fc936ee3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ec645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the in-situ datastreams and output directory\n",
    "insitu_stream = {'bnfmetM1.b1' : INSITU_DIR + 'bnfmetM1.b1',\n",
    "                 'bnfmetS20.b1' : INSITU_DIR + \"bnfmetS20.b1\",\n",
    "                 \"bnfmetS30.b1\" : INSITU_DIR + \"bnfmetS30.b1\",\n",
    "                 \"bnfmetS40.b1\" : INSITU_DIR + \"bnfmetS40.b1\",\n",
    "                 \"bnfsondewnpnM1.b1\" : INSITU_DIR + \"bnfsondewnpnM1.b1\",\n",
    "                 \"bnfwbpluvio2M1.a1\" : INSITU_DIR + \"bnfwbpluvio2M1.a1\",\n",
    "                 \"bnfldquantsM1.c1\" : INSITU_DIR + \"bnfldquantsM1.c1\",\n",
    "                 \"bnfldquantsS30.c1\" : INSITU_DIR + \"bnfldquantsS30.c1\",\n",
    "                 \"bnfvdisquantsM1.c1\" : INSITU_DIR + \"bnfvdisquantsM1.c1\",\n",
    "                 \"bnfmetwxtS13.b1\" : INSITU_DIR + \"bnfmetwxtS13.b1\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables to drop from RadCLss from the respective datastreams \n",
    "discard_var = {'radar' : ['classification_mask',\n",
    "                          'censor_mask',\n",
    "                          'uncorrected_copol_correlation_coeff',\n",
    "                          'uncorrected_differential_phase',\n",
    "                          'uncorrected_differential_reflectivity',\n",
    "                          'uncorrected_differential_reflectivity_lag_1',\n",
    "                          'uncorrected_mean_doppler_velocity_h',\n",
    "                          'uncorrected_mean_doppler_velocity_v',\n",
    "                          'uncorrected_reflectivity_h',\n",
    "                          'uncorrected_reflectivity_v',\n",
    "                          'uncorrected_spectral_width_h',\n",
    "                          'uncorrected_spectral_width_v',\n",
    "                          'clutter_masked_velocity',\n",
    "                          'gate_id',\n",
    "                          'ground_clutter',\n",
    "                          'partial_beam_blockage',\n",
    "                          'cumulative_beam_blockage',\n",
    "                          'unfolded_differential_phase',\n",
    "                          'path_integrated_attenuation',\n",
    "                          'path_integrated_differential_attenuation',\n",
    "                          'unthresholded_power_copolar_v',\n",
    "                          'unthresholded_power_copolar_h',\n",
    "                          'specific_differential_phase',\n",
    "                          'specific_differential_attenuation',\n",
    "                          'reflectivity_v',\n",
    "                          'reflectivity',\n",
    "                          'mean_doppler_velocity_v',\n",
    "                          'mean_doppler_velocity',\n",
    "                          'differential_reflectivity_lag_1',\n",
    "                          'differential_reflectivity',\n",
    "                          'differential_phase',\n",
    "                          'normalized_coherent_power',\n",
    "                          'normalized_coherent_power_v',\n",
    "                          'signal_to_noise_ratio_copolar_h',\n",
    "                          'signal_to_noise_ratio_copolar_v',\n",
    "                          'specific_attenuation',\n",
    "                          'spectral_width',\n",
    "                          'spectral_width_v',\n",
    "                          'sounding_temperature',\n",
    "                          'signal_to_noise_ratio',\n",
    "                          'velocity_texture',\n",
    "                          'simulated_velocity',\n",
    "                          'height_over_iso0'\n",
    "                ],\n",
    "                'met' : ['base_time', 'time_offset', 'time_bounds', 'logger_volt',\n",
    "                        'logger_temp', 'qc_logger_temp', 'lat', 'lon', 'alt', 'qc_temp_mean',\n",
    "                        'qc_rh_mean', 'qc_vapor_pressure_mean', 'qc_wspd_arith_mean', 'qc_wspd_vec_mean',\n",
    "                        'qc_wdir_vec_mean', 'qc_pwd_mean_vis_1min', 'qc_pwd_mean_vis_10min', 'qc_pwd_pw_code_inst',\n",
    "                        'qc_pwd_pw_code_15min', 'qc_pwd_pw_code_1hr', 'qc_pwd_precip_rate_mean_1min',\n",
    "                        'qc_pwd_cumul_rain', 'qc_pwd_cumul_snow', 'qc_org_precip_rate_mean', 'qc_tbrg_precip_total',\n",
    "                        'qc_tbrg_precip_total_corr', 'qc_logger_volt', 'qc_logger_temp', 'qc_atmos_pressure', \n",
    "                        'pwd_pw_code_inst', 'pwd_pw_code_15min', 'pwd_pw_code_1hr', 'temp_std', 'rh_std',\n",
    "                        'vapor_pressure_std', 'wdir_vec_std', 'tbrg_precip_total', 'org_precip_rate_mean',\n",
    "                        'pwd_mean_vis_1min', 'pwd_mean_vis_10min', 'pwd_precip_rate_mean_1min', 'pwd_cumul_rain',\n",
    "                        'pwd_cumul_snow', 'pwd_err_code'\n",
    "                ],\n",
    "                'sonde' : ['base_time', 'time_offset', 'lat', 'lon', 'qc_pres',\n",
    "                           'qc_tdry', 'qc_dp', 'qc_wspd', 'qc_deg', 'qc_rh',\n",
    "                           'qc_u_wind', 'qc_v_wind', 'qc_asc', \"wstat\", \"asc\"\n",
    "                ],\n",
    "                'pluvio' : ['base_time', 'time_offset', 'load_cell_temp', 'heater_status',\n",
    "                            'elec_unit_temp', 'supply_volts', 'orifice_temp', 'volt_min',\n",
    "                            'ptemp', 'lat', 'lon', 'alt', 'maintenance_flag', 'reset_flag', \n",
    "                            'qc_rh_mean', 'pluvio_status', 'bucket_rt', 'accum_total_nrt'\n",
    "                ],\n",
    "                'ldquants' : ['specific_differential_attenuation_xband20c',\n",
    "                              'specific_differential_attenuation_kaband20c',\n",
    "                              'specific_differential_attenuation_sband20c',\n",
    "                              'bringi_conv_stra_flag',\n",
    "                              'exppsd_slope',\n",
    "                              'norm_num_concen',\n",
    "                              'num_concen',\n",
    "                              'gammapsd_shape',\n",
    "                              'gammapsd_slope',\n",
    "                              'mean_doppler_vel_wband20c',\n",
    "                              'mean_doppler_vel_kaband20c',\n",
    "                              'mean_doppler_vel_xband20c',\n",
    "                              'mean_doppler_vel_sband20c',\n",
    "                              'specific_attenuation_kaband20c',\n",
    "                              'specific_attenuation_xband20c',\n",
    "                              'specific_attenuation_sband20c',\n",
    "                              'specific_differential_phase_kaband20c',\n",
    "                              'specific_differential_phase_xband20c',\n",
    "                              'specific_differential_phase_sband20c',\n",
    "                              'differential_reflectivity_kaband20c',\n",
    "                              'differential_reflectivity_xband20c',\n",
    "                              'differential_reflectivity_sband20c',\n",
    "                              'reflectivity_factor_wband20c',\n",
    "                              'reflectivity_factor_kaband20c',\n",
    "                              'reflectivity_factor_xband20c',\n",
    "                              'reflectivity_factor_sband20c',\n",
    "                              'bringi_conv_stra_flag',\n",
    "                              'time_offset',\n",
    "                              'base_time',\n",
    "                              'lat',\n",
    "                              'lon',\n",
    "                              'alt'\n",
    "                ],\n",
    "                'vdisquants' : ['specific_differential_attenuation_xband20c',\n",
    "                                'specific_differential_attenuation_kaband20c',\n",
    "                                'specific_differential_attenuation_sband20c',\n",
    "                                'bringi_conv_stra_flag',\n",
    "                                'exppsd_slope',\n",
    "                                'norm_num_concen',\n",
    "                                'num_concen',\n",
    "                                'gammapsd_shape',\n",
    "                                'gammapsd_slope',\n",
    "                                'mean_doppler_vel_wband20c',\n",
    "                                'mean_doppler_vel_kaband20c',\n",
    "                                'mean_doppler_vel_xband20c',\n",
    "                                'mean_doppler_vel_sband20c',\n",
    "                                'specific_attenuation_kaband20c',\n",
    "                                'specific_attenuation_xband20c',\n",
    "                                'specific_attenuation_sband20c',\n",
    "                                'specific_differential_phase_kaband20c',\n",
    "                                'specific_differential_phase_xband20c',\n",
    "                                'specific_differential_phase_sband20c',\n",
    "                                'differential_reflectivity_kaband20c',\n",
    "                                'differential_reflectivity_xband20c',\n",
    "                                'differential_reflectivity_sband20c',\n",
    "                                'reflectivity_factor_wband20c',\n",
    "                                'reflectivity_factor_kaband20c',\n",
    "                                'reflectivity_factor_xband20c',\n",
    "                                'reflectivity_factor_sband20c',\n",
    "                                'bringi_conv_stra_flag',\n",
    "                                'time_offset',\n",
    "                                'base_time',\n",
    "                                'lat',\n",
    "                                'lon',\n",
    "                                'alt'\n",
    "                ],\n",
    "                'wxt' : ['base_time',\n",
    "                         'time_offset',\n",
    "                         'time_bounds',\n",
    "                         'temp_mean',\n",
    "                         'qc_temp_mean',\n",
    "                         'temp_std',\n",
    "                         'rh_mean',\n",
    "                         'qc_rh_mean',\n",
    "                         'rh_std',\n",
    "                         'atmos_pressure',\n",
    "                         'qc_atmos_pressure',\n",
    "                         'wspd_arith_mean',\n",
    "                         'qc_wspd_arith_mean',\n",
    "                         'wspd_vec_mean',\n",
    "                         'qc_wspd_vec_mean',\n",
    "                         'wdir_vec_mean',\n",
    "                         'qc_wdir_vec_mean',\n",
    "                         'wdir_vec_std',\n",
    "                         'qc_wxt_precip_rate_mean',\n",
    "                         'qc_wxt_cumul_precip',\n",
    "                         'logger_volt',\n",
    "                         'qc_logger_volt',\n",
    "                         'logger_temp',\n",
    "                         'qc_logger_temp',\n",
    "                         'lat',\n",
    "                         'lon',\n",
    "                         'alt'\n",
    "                ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30688245-b868-4ff5-ada3-a810fd7b2b82",
   "metadata": {},
   "source": [
    "## Define Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de88caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_points(nfile, **kwargs):\n",
    "    \"\"\"\n",
    "    Subset a radar file for a set of latitudes and longitudes\n",
    "    utilizing Py-ART's column-vertical-profile functionality.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        Path to the radar file to extract columns from\n",
    "    nsonde : list\n",
    "        List containing file paths to the desired sonde file to merge\n",
    "\n",
    "    Calls\n",
    "    -----\n",
    "    radar_start_time\n",
    "    merge_sonde\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ds : xarray DataSet\n",
    "        Xarray Dataset containing the radar column above a give set of locations\n",
    "    \n",
    "    \"\"\"\n",
    "    ds = None\n",
    "    \n",
    "    # Define the splash locations [lon,lat]\n",
    "    M1 = [34.34525, -87.33842]\n",
    "    S4 = [34.46451,\t-87.23598]\n",
    "    S20 = [34.65401, -87.29264]\n",
    "    S30\t= [34.38501, -86.92757]\n",
    "    S40\t= [34.17932, -87.45349]\n",
    "    S13 = [34.343889, -87.350556]\n",
    "\n",
    "    sites    = [\"M1\", \"S4\", \"S20\", \"S30\", \"S40\", \"S13\"]\n",
    "    site_alt = [293, 197, 178, 183, 236, 286]\n",
    "\n",
    "    # Zip these together!\n",
    "    lats, lons = list(zip(M1,\n",
    "                          S4,\n",
    "                          S20,\n",
    "                          S30,\n",
    "                          S40,\n",
    "                          S13))\n",
    "    try:\n",
    "        # Read in the file\n",
    "        radar = pyart.io.read(nfile)\n",
    "        # Check for single sweep scans\n",
    "        if np.ma.is_masked(radar.sweep_start_ray_index[\"data\"][1:]):\n",
    "            radar.sweep_start_ray_index[\"data\"] = np.ma.array([0])\n",
    "            radar.sweep_end_ray_index[\"data\"] = np.ma.array([radar.nrays])\n",
    "    except:\n",
    "        radar = None\n",
    "\n",
    "    if radar:\n",
    "        if radar.scan_type != \"rhi\":\n",
    "            if radar.time['data'].size > 0:\n",
    "                # Easier to map the nearest sonde file to radar gates before extraction\n",
    "                if 'sonde' in kwargs:\n",
    "                    # variables to discard when reading in the sonde file\n",
    "                    exclude_sonde = ['base_time', 'time_offset', 'lat', 'lon', 'qc_pres',\n",
    "                                    'qc_tdry', 'qc_dp', 'qc_wspd', 'qc_deg', 'qc_rh',\n",
    "                                    'qc_u_wind', 'qc_v_wind', 'qc_asc']\n",
    "        \n",
    "                    # find the nearest sonde file to the radar start time\n",
    "                    radar_start = datetime.datetime.strptime(nfile.split('/')[-1].split('.')[-3] + '.' + nfile.split('/')[-1].split('.')[-2], \n",
    "                                                            '%Y%m%d.%H%M%S'\n",
    "                    )\n",
    "                    sonde_start = [datetime.datetime.strptime(xfile.split('/')[-1].split('.')[2] + \n",
    "                                                              '-' + \n",
    "                                                              xfile.split('/')[-1].split('.')[3], \n",
    "                                                              '%Y%m%d-%H%M%S') for xfile in kwargs['sonde']\n",
    "                    ]\n",
    "                    # difference in time between radar file and each sonde file\n",
    "                    start_diff = [radar_start - sonde for sonde in sonde_start]\n",
    "\n",
    "                    # merge the sonde file into the radar object\n",
    "                    ds_sonde = act.io.read_arm_netcdf(kwargs['sonde'][start_diff.index(min(start_diff))], \n",
    "                                                      cleanup_qc=True, \n",
    "                                                      drop_variables=exclude_sonde)\n",
    "   \n",
    "                    # create list of variables within sonde dataset to add to the radar file\n",
    "                    for var in list(ds_sonde.keys()):\n",
    "                        if var != \"alt\":\n",
    "                            z_dict, sonde_dict = pyart.retrieve.map_profile_to_gates(ds_sonde.variables[var],\n",
    "                                                                                    ds_sonde.variables['alt'],\n",
    "                                                                                    radar)\n",
    "                        # add the field to the radar file\n",
    "                        radar.add_field_like('corrected_reflectivity', \"sonde_\" + var,  sonde_dict['data'], replace_existing=True)\n",
    "                        radar.fields[\"sonde_\" + var][\"units\"] = sonde_dict[\"units\"]\n",
    "                        radar.fields[\"sonde_\" + var][\"long_name\"] = sonde_dict[\"long_name\"]\n",
    "                        radar.fields[\"sonde_\" + var][\"standard_name\"] = sonde_dict[\"standard_name\"]\n",
    "                        radar.fields[\"sonde_\" + var][\"datastream\"] = ds_sonde.datastream\n",
    "\n",
    "                    del radar_start, sonde_start, ds_sonde\n",
    "                    del z_dict, sonde_dict\n",
    "        \n",
    "                column_list = []\n",
    "                for lat, lon in zip(lats, lons):\n",
    "                    # Make sure we are interpolating from the radar's location above sea level\n",
    "                    # NOTE: interpolating throughout Troposphere to match sonde to in the future\n",
    "                    try:\n",
    "                        da = (\n",
    "                            pyart.util.columnsect.column_vertical_profile(radar, lat, lon)\n",
    "                            .interp(height=np.arange(500, 8500, 250))\n",
    "                        )\n",
    "                    except ValueError:\n",
    "                        da = pyart.util.columnsect.column_vertical_profile(radar, lat, lon)\n",
    "                        # drop the NaNs (and associated fields) from the extraction\n",
    "                        da = da.isel(height=~np.isnan(da.height))\n",
    "                        # interpolate to the same profile \n",
    "                        da = da.interp(height=np.arange(500, 8500, 250))\n",
    "\n",
    "                    # Interpolate NaNs out\n",
    "                    da = da.interpolate_na(dim=\"height\", method=\"linear\", fill_value=\"extrapolate\")   \n",
    "                    # Add the latitude and longitude of the extracted column\n",
    "                    da[\"lat\"], da[\"lon\"] = lat, lon\n",
    "                    # Convert timeoffsets to timedelta object and precision on datetime64\n",
    "                    da.time_offset.data = da.time_offset.values.astype(\"timedelta64[s]\")\n",
    "                    da.base_time.data = da.base_time.values.astype(\"datetime64[s]\")\n",
    "                    # Time is based off the start of the radar volume\n",
    "                    da[\"gate_time\"] = da.base_time.values + da.isel(height=0).time_offset.values\n",
    "                    column_list.append(da)\n",
    "        \n",
    "                # Concatenate the extracted radar columns for this scan across all sites    \n",
    "                ds = xr.concat([data for data in column_list if data], dim='station')\n",
    "                ds[\"station\"] = sites\n",
    "                # Assign the Main and Supplemental Site altitudes\n",
    "                ds = ds.assign(alt=(\"station\", site_alt))\n",
    "                # Add attributes for Time, Latitude, Longitude, and Sites\n",
    "                ds.gate_time.attrs.update(long_name=('Time in Seconds that Cooresponds to the Start'\n",
    "                                                    + \" of each Individual Radar Volume Scan before\"\n",
    "                                                    + \" Concatenation\"),\n",
    "                                          description=('Time in Seconds that Cooresponds to the Minimum'\n",
    "                                                    + ' Height Gate'))\n",
    "                ds.time_offset.attrs.update(long_name=(\"Time in Seconds Since Midnight\"),\n",
    "                                            description=(\"Time in Seconds Since Midnight that Cooresponds\"\n",
    "                                                        + \"to the Center of Each Height Gate\"\n",
    "                                                        + \"Above the Target Location \")\n",
    "                                            )\n",
    "                ds.station.attrs.update(long_name=\"Bankhead National Forest AMF-3 In-Situ Ground Observation Station Identifers\")\n",
    "                ds.lat.attrs.update(long_name='Latitude of BNF AMF-3 Ground Observation Site',\n",
    "                                         units='Degrees North')\n",
    "                ds.lon.attrs.update(long_name='Longitude of BNF AMF-3 Ground Observation Site',\n",
    "                                          units='Degrees East')\n",
    "                ds.alt.attrs.update(long_name=\"Altitude above mean sea level for each station\",\n",
    "                                          units=\"m\")\n",
    "                # delete the radar to free up memory\n",
    "                del radar, column_list, da\n",
    "            else:\n",
    "                # delete the rhi file\n",
    "                del radar\n",
    "        else:\n",
    "            del radar\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_datasets_act(column, \n",
    "                       ground, \n",
    "                       site, \n",
    "                       discard, \n",
    "                       resample='sum', \n",
    "                       DataSet=False,\n",
    "                       prefix=None):\n",
    "    \"\"\"\n",
    "    Time synchronization of a Ground Instrumentation Dataset to \n",
    "    a Radar Column for Specific Locations using the ARM ACT package\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    column : Xarray DataSet\n",
    "        Xarray DataSet containing the extracted radar column above multiple locations.\n",
    "        Dimensions should include Time, Height, Site\n",
    "             \n",
    "    ground : str; Xarray DataSet\n",
    "        String containing the path of the ground instrumentation file that is desired\n",
    "        to be included within the extracted radar column dataset. \n",
    "        If DataSet is set to True, ground is Xarray Dataset and will skip I/O. \n",
    "             \n",
    "    site : str\n",
    "        Location of the ground instrument. Should be included within the filename. \n",
    "        \n",
    "    discard : list\n",
    "        List containing the desired input ground instrumentation variables to be \n",
    "        removed from the xarray DataSet. \n",
    "    \n",
    "    resample : str\n",
    "        Mathematical operational for resampling ground instrumentation to the radar time.\n",
    "        Default is to sum the data across the resampling period. Checks for 'mean' or \n",
    "        to 'skip' altogether. \n",
    "    \n",
    "    DataSet : boolean\n",
    "        Boolean flag to determine if ground input is an Xarray Dataset.\n",
    "        Set to True if ground input is Xarray DataSet. \n",
    "\n",
    "    prefix : str\n",
    "        prefix for the desired spelling of variable names for the input\n",
    "        datastream (to fix duplicate variable names between instruments)\n",
    "             \n",
    "    Returns\n",
    "    -------\n",
    "    ds : Xarray DataSet\n",
    "        Xarray Dataset containing the time-synced in-situ ground observations with\n",
    "        the inputed radar column \n",
    "    \"\"\"\n",
    "     # Check to see if input is xarray DataSet or a file path\n",
    "    if DataSet == True:\n",
    "        grd_ds = ground\n",
    "    else:\n",
    "        # Read in the file using ACT\n",
    "        grd_ds = act.io.read_arm_netcdf(ground, cleanup_qc=True, drop_variables=discard)\n",
    "        # Default are Lazy Arrays; convert for matching with column\n",
    "        grd_ds = grd_ds.compute()\n",
    "        # check if a list containing new variable names exists. \n",
    "        if prefix:\n",
    "            grd_ds = grd_ds.rename_vars({v: f\"{prefix}{v}\" for v in grd_ds.data_vars})\n",
    "        \n",
    "    # Remove Base_Time before Resampling Data since you can't force 1 datapoint to 5 min sum\n",
    "    if 'base_time' in grd_ds.data_vars:\n",
    "        del grd_ds['base_time']\n",
    "        \n",
    "    # Check to see if height is a dimension within the ground instrumentation. \n",
    "    # If so, first interpolate heights to match radar, before interpolating time.\n",
    "    if 'height' in grd_ds.dims:\n",
    "        grd_ds = grd_ds.interp(height=np.arange(3150, 10050, 50), method='linear')\n",
    "        \n",
    "    # Resample the ground data to 5 min and interpolate to the CSU X-Band time. \n",
    "    # Keep data variable attributes to help distingish between instruments/locations\n",
    "    if resample.split('=')[-1] == 'mean':\n",
    "        matched = grd_ds.resample(time='5Min', \n",
    "                                  closed='right').mean(keep_attrs=True).interp(time=column.time, \n",
    "                                                                               method='linear')\n",
    "    elif resample.split('=')[-1] == 'skip':\n",
    "        matched = grd_ds.interp(time=column.time, method='linear')\n",
    "    else:\n",
    "        matched = grd_ds.resample(time='5Min', \n",
    "                                  closed='right').sum(keep_attrs=True).interp(time=column.time, \n",
    "                                                                              method='linear')\n",
    "    \n",
    "    # Add SAIL site location as a dimension for the Pluvio data\n",
    "    matched = matched.assign_coords(coords=dict(station=site))\n",
    "    matched = matched.expand_dims('station')\n",
    "   \n",
    "    # Remove Lat/Lon Data variables as it is included within the Matched Dataset with Site Identfiers\n",
    "    if 'lat' in matched.data_vars:\n",
    "        del matched['lat']\n",
    "    if 'lon' in matched.data_vars:\n",
    "        del matched['lon']\n",
    "    if 'alt' in matched.data_vars:\n",
    "        del matched['alt']\n",
    "        \n",
    "    # Update the individual Variables to Hold Global Attributes\n",
    "    # global attributes will be lost on merging into the matched dataset.\n",
    "    # Need to keep as many references and descriptors as possible\n",
    "    for var in matched.data_vars:\n",
    "        matched[var].attrs.update(source=matched.datastream)\n",
    "        \n",
    "    # Merge the two DataSets\n",
    "    column = xr.merge([column, matched])\n",
    "   \n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2ec20-bb15-441a-b726-38f29cf63752",
   "metadata": {},
   "source": [
    "## Find / Download In-Situ Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc35db1-9ef4-4838-8f81-2b93d798540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the ACT module for downloading data from the ARM web service\n",
    "for insitu in insitu_stream:\n",
    "    #if insitu != \"bnfsondewnpnM1.b1\":\n",
    "        results = act.discovery.download_arm_data(ARM_USERNAME, \n",
    "                                                  ARM_TOKEN, \n",
    "                                                  insitu, \n",
    "                                                  DATE, \n",
    "                                                  DATE, \n",
    "                                                  output=insitu_stream[insitu])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00789bb-406b-4edf-b2f2-d03e58166e3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Locate the CMAC Processed CSAPR-2 and Extract all Radar Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd81b915-b600-4b18-ab78-37a63de18b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With the user defined RADAR_DIR, grab all the XPRECIPRADAR CMAC files for the defined DATE\n",
    "file_list = sorted(glob.glob(RADAR_DIR + 'bnfcsapr2cmacS3.c1.' + DATE.replace('-', '') + '*.nc'))\n",
    "file_list[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78763f9-c320-469b-aed1-a4b50477a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Start up a Dask Cluster\n",
    "cluster = LocalCluster(n_workers=4)\n",
    "with Client(cluster) as client:\n",
    "    future = client.map(subset_points, file_list)\n",
    "    my_data = client.gather(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aae040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all extracted columns across time dimension to form daily timeseries\n",
    "ds = xr.concat([data for data in my_data if data], dim=\"time\")\n",
    "ds['time'] = ds.sel(station=\"M1\").base_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf06b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd98940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.drop_vars(discard_var[\"radar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93866f",
   "metadata": {},
   "source": [
    "## RadCLss Corrected Reflectivity Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(3, 2, figsize=[16, 10])\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "\n",
    "fig.suptitle(\"BNF RadCLss - \" + DATE)\n",
    "\n",
    "ds.sel(station=\"M1\").sel(time=slice(\"2025-05-24T14:00:00\", \"2025-05-24T17:30:00\")).corrected_reflectivity.plot(y=\"height\", ax=axarr[0, 0], vmin=-30, vmax=65, cmap=\"ChaseSpectral\")\n",
    "ds.sel(station=\"S4\").sel(time=slice(\"2025-05-24T14:00:00\", \"2025-05-24T17:30:00\")).corrected_reflectivity.plot(y=\"height\", ax=axarr[0, 1], vmin=-30, vmax=65, cmap=\"ChaseSpectral\")\n",
    "ds.sel(station=\"S20\").sel(time=slice(\"2025-05-24T14:00:00\", \"2025-05-24T17:30:00\")).corrected_reflectivity.plot(y=\"height\", ax=axarr[1, 0], vmin=-30, vmax=65, cmap=\"ChaseSpectral\")\n",
    "ds.sel(station=\"S30\").sel(time=slice(\"2025-05-24T14:00:00\", \"2025-05-24T17:30:00\")).corrected_reflectivity.plot(y=\"height\", ax=axarr[1, 1], vmin=-30, vmax=65, cmap=\"ChaseSpectral\")\n",
    "ds.sel(station=\"S40\").sel(time=slice(\"2025-05-24T14:00:00\", \"2025-05-24T17:30:00\")).corrected_reflectivity.plot(y=\"height\", ax=axarr[2, 0], vmin=-30, vmax=65, cmap=\"ChaseSpectral\")\n",
    "ds.sel(station=\"S13\").sel(time=slice(\"2025-05-24T14:00:00\", \"2025-05-24T17:30:00\")).corrected_reflectivity.plot(y=\"height\", ax=axarr[2, 1], vmin=-30, vmax=65, cmap=\"ChaseSpectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8eff74",
   "metadata": {},
   "source": [
    "## Merge in the In-Situ Datastreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a86978",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream in insitu_stream:\n",
    "    if \"bnfmet\" in stream:\n",
    "        if \"wxt\" not in stream:\n",
    "            if \"M1\" in stream:\n",
    "                met_list = sorted(glob.glob(insitu_stream[stream] + \"/*\" + DATE.replace('-', '') + '*.cdf'))\n",
    "                if met_list:\n",
    "                    ds = match_datasets_act(ds, \n",
    "                                            met_list[0],\n",
    "                                            \"M1\", \n",
    "                                            discard=discard_var['met'])\n",
    "            else:\n",
    "                met_list = sorted(glob.glob(insitu_stream[stream] + \"/*\" + DATE.replace('-', '') + '*.cdf'))\n",
    "                met_site = met_list[0].split(\"/\")[-1].split(\".\")[0][-3:]\n",
    "                if met_list:\n",
    "                    ds = match_datasets_act(ds, \n",
    "                                            met_list[0], \n",
    "                                            met_site, \n",
    "                                            discard=discard_var['met'])\n",
    "    elif \"bnfwbpluvio\" in stream:\n",
    "        insitu_list = sorted(glob.glob(insitu_stream[stream] + \"/*\" + DATE.replace('-', '') + '*.nc'))\n",
    "        if insitu_list:\n",
    "                ds = match_datasets_act(ds, \n",
    "                                        insitu_list[0], \n",
    "                                        \"M1\", \n",
    "                                        discard=discard_var['pluvio'])\n",
    "    elif \"bnfldquants\" in stream:\n",
    "        if \"M1\" in stream:\n",
    "            insitu_list = sorted(glob.glob(insitu_stream[stream] + \"/*\" + DATE.replace('-', '') + '*.nc'))\n",
    "            if insitu_list:\n",
    "                ds = match_datasets_act(ds, \n",
    "                                        insitu_list[0], \n",
    "                                        \"M1\", \n",
    "                                        discard=discard_var['ldquants'], \n",
    "                                        resample=\"mean\",\n",
    "                                        prefix=\"ldquants_\")\n",
    "        if \"S30\" in stream:\n",
    "            insitu_list = sorted(glob.glob(insitu_stream[\"bnfldquantsS30.c1\"] + \"/*\" + DATE.replace('-', '') + '*.nc'))\n",
    "            if insitu_list:\n",
    "                ds = match_datasets_act(ds, \n",
    "                                        insitu_list[0], \n",
    "                                        \"S30\", \n",
    "                                        discard=discard_var['ldquants'], \n",
    "                                        resample=\"mean\",\n",
    "                                        prefix=\"ldquants_\")\n",
    "    elif \"sonde\" in stream:\n",
    "        insitu_list = sorted(glob.glob(insitu_stream[stream] + \"/*\" + DATE.replace('-', '') + '*.cdf'))\n",
    "        if insitu_list:\n",
    "                ds = match_datasets_act(ds, \n",
    "                                        insitu_list[0], \n",
    "                                        \"M1\", \n",
    "                                        discard=discard_var['sonde'],\n",
    "                                        prefix=\"sonde_\")\n",
    "    elif \"wxt\" in stream:\n",
    "         if \"S13\" in stream:\n",
    "            insitu_list = sorted(glob.glob(insitu_stream[stream] + \"/*\" + DATE.replace('-', '') + '*.nc'))\n",
    "            if insitu_list:\n",
    "                ds = match_datasets_act(ds, \n",
    "                                        insitu_list[0], \n",
    "                                        \"S13\", \n",
    "                                        discard=discard_var['wxt'], \n",
    "                                        resample=\"mean\",\n",
    "                                        prefix=\"wxt_\")\n",
    "    elif \"bnfvdisquants\" in stream:\n",
    "        if \"M1\" in stream:\n",
    "            insitu_list = sorted(glob.glob(insitu_stream[stream] + \"/*\" + DATE.replace('-', '') + '*.nc'))\n",
    "            if insitu_list:\n",
    "                ds = match_datasets_act(ds, \n",
    "                                        insitu_list[0], \n",
    "                                        \"M1\", \n",
    "                                        discard=discard_var['vdisquants'], \n",
    "                                        resample=\"mean\",\n",
    "                                        prefix=\"vdisquants_\")\n",
    "    else:\n",
    "         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [\"base_time\", \"time_offset\", \"time\", \"height\", \"station\"]           # the two you want first\n",
    "last  = [\"latitude\", \"longitude\", \"alt\"]   # the three you want last\n",
    "\n",
    "# Keep only data variables, preserve order, and drop the ones already in first/last\n",
    "middle = [v for v in ds.data_vars if v not in first + last]\n",
    "\n",
    "ordered = first + middle + last\n",
    "#ds = ds[ordered]   # returns a new Dataset with vars in that order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[ordered]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f5afd",
   "metadata": {},
   "source": [
    "## Save the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a19a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to check why xarray does not like unit attribute for time\n",
    "del ds[\"time\"].attrs[\"units\"]\n",
    "del ds[\"time_offset\"].attrs[\"units\"]\n",
    "del ds[\"base_time\"].attrs[\"units\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a1bd1",
   "metadata": {},
   "source": [
    "### Apply the DOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a filename\n",
    "ds.to_netcdf('data/bnf-csapr2-radclss.c2.' + DATE.replace('-', '') + '.000000.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558096c3-19e2-4a1e-9452-08bb6e911277",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Surface Meteorological Instrumentation (MET)\n",
    "- Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
    "(MET), 2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term\n",
    "Mobile Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) **(M1)**.\n",
    "Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1786358\n",
    "\n",
    "- Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
    "(MET), 2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term\n",
    "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
    "Courtland **(S20)**. Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1786358\n",
    "\n",
    "- Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
    "(MET), 2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term\n",
    "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
    "Falkville **(S30)**. Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1786358\n",
    "\n",
    "- Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
    "(MET), 2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term\n",
    "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
    "Double Springs **(S40)**. Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1786358\n",
    "\n",
    "### Balloon-Borne Sounding System (SONDEWNPN)\n",
    "- Keeler, E., Burk, K., & Kyrouac, J. Balloon-Borne Sounding System (SONDEWNPN),\n",
    "2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term Mobile\n",
    "Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) **(M1)**. Atmospheric\n",
    "Radiation Measurement (ARM) User Facility. https://doi.org/10.5439/1595321\n",
    "\n",
    "### Weighing Bucket Preciptiation Gauge (WBPLUVIO2)\n",
    "- Zhu, Z., Wang, D., Jane, M., Cromwell, E., Sturm, M., Irving, K., & Delamere, J.\n",
    "Weighing Bucket Precipitation Gauge (WBPLUVIO2), 2025-03-05 to 2025-03-05,\n",
    "Bankhead National Forest, AL, USA; Long-term Mobile Facility (BNF), Bankhead\n",
    "National Forest, AL, AMF3 (Main Site) **(M1)**. Atmospheric Radiation Measurement\n",
    "(ARM) User Facility. https://doi.org/10.5439/1338194\n",
    "\n",
    "### Laser Disdrometer Quantities (LDQUANTS)\n",
    "- Hardin, J., Giangrande, S., & Zhou, A. Laser Disdrometer Quantities (LDQUANTS),\n",
    "2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term Mobile\n",
    "Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) **(M1)**. Atmospheric\n",
    "Radiation Measurement (ARM) User Facility. https://doi.org/10.5439/1432694\n",
    "\n",
    "- Hardin, J., Giangrande, S., & Zhou, A. Laser Disdrometer Quantities (LDQUANTS),\n",
    "2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term Mobile\n",
    "Facility (BNF), Bankhead National Forest, AL, Supplemental facility at Falkville\n",
    "**(S30)**. Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1432694\n",
    "\n",
    "### Video Disdrometer Quantities (VDISQUANTS)\n",
    "- Hardin, J., Giangrande, S., Fairless, T., & Zhou, A. Video Disdrometer VAP\n",
    "(VDISQUANTS), 2025-05-24 to 2025-05-24, Bankhead National Forest, AL, USA; Long-\n",
    "term Mobile Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) (M1).\n",
    "Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1592683\n",
    "\n",
    "### Vaisala Weather Transmitter (METWXT)\n",
    "- Kyrouac, J., & Shi, Y. WXT520/530 Meteorological Instrument System (METWXT),\n",
    "2025-05-24 to 2025-05-24, Bankhead National Forest, AL, USA; Long-term Mobile\n",
    "Facility (BNF), Bankhead National Forest, AL, Supplemental facility for STAMP2\n",
    "near Tower Site (S13). Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1455447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f873d74-9e73-43a2-abe0-e7a6dd20e5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amf3-radar-examples-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
