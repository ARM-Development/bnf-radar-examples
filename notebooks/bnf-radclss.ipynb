{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2637142-0fde-46c9-b5c3-4c5c4e5fef80",
   "metadata": {},
   "source": [
    "<img src=\"images/arm_logo.png\" width=500 alt=\"ARM Logo\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f0bb8e-facf-4d8d-bf47-ba813d6b6d09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bankhead National Forest - RadClss Example\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Extracted Radar Columns and In-Situ Sensors (RadClss) Value-Added Product (VAP) is\n",
    "a dataset containing in-situ ground observations matched to CSAPR-2 radar columns above ARM Mobile Facility (AMF-3) supplemental sites of interest. \n",
    "\n",
    "RadCLss is intended to provide a dataset for algorthim development and validation of precipitation retrievals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4f954-2b6a-436c-ab90-d2905dc6e69c",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro to Cartopy](https://foundations.projectpythia.org/core/cartopy/cartopy.html) | Necessary | |\n",
    "| [Understanding of NetCDF](https://foundations.projectpythia.org/core/data-formats/netcdf-cf.html) | Helpful | Familiarity with metadata structure |\n",
    "| [GeoPandas](https://geopandas.org/en/stable/docs.html) | Necessary | Familiarity with Geospatial Plotting|\n",
    "| [Py-ART / Radar Foundations](https://projectpythia.org/radar-cookbook/README.html) | Necessary | Basics of Weather Radar | \n",
    "\n",
    "- **Time to learn**: 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099ee1f-4dca-4b19-8192-0ecef80df30a",
   "metadata": {},
   "source": [
    "## Current List of Supported Sites of Interest\n",
    "| Site  | Lat   | Lon   |\n",
    "| ----- | ----- | ----- |\n",
    "| M1    | 34.34525 | -87.33842 |\n",
    "| S4    | 34.46451 | -87.23598 |\n",
    "| S20   | 34.65401 | -87.29264 |\n",
    "| S30   | 34.38501 | -86.92757 |\n",
    "| S40   | 34.17932 | -87.45349 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1626c58-6fda-42b9-bbf3-1dbdd4b81f5e",
   "metadata": {},
   "source": [
    "<img src=\"images/bnf-in-situ-locations.png\" width=1500 alt=\"BNF Sensors\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2465bc-4681-489e-ac79-ee8330c94dd0",
   "metadata": {},
   "source": [
    "## Current List of Supported In-Situ Ground Observations\n",
    "- Surface Meteorological Instrumentation [MET] (DOI: 10.5439/1786358)\n",
    "    - M1, S20, S30, S40\n",
    "- Balloon-borne sounding system [SONDEWNPN] (DOI: 10.5439/1595321)*\n",
    "    - M1 \n",
    "\n",
    "## Planned List of Supported In-Situ Ground Observations\n",
    "- *Pluvio Weighing Bucket Precipitation Gauge [WBPLUVIO2] (DOI: )*\n",
    "- *Surface Meteorological Instrumentation [MET] (DOI: )*\n",
    "- *Laser Disdrometer [LD] (DOI: )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22ab264-3cec-4824-b8ee-712c2e7a664c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "import act\n",
    "import pyart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa066eb",
   "metadata": {},
   "source": [
    "## Define Processing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7b71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired processing date for the BNF CSAPR-2 in YYYY-MM-DD format.\n",
    "DATE = \"2025-01-09\"\n",
    "# Define the directory where the BNF CSAPR-2 CMAC files are located.\n",
    "##RADAR_DIR = \"/gpfs/wolf2/arm/atm124/proj-shared/bnf/bnfcsapr2cmacS3.c1/\"\n",
    "RADAR_DIR = \"/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/\"\n",
    "# Define an output directory for downloaded ground instrumentation\n",
    "##INSITU_DIR = '/gpfs/wolf2/arm/atm124/proj-shared/bnf/in_situ/'\n",
    "INSITU_DIR = \"/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0b9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ARM Username and ARM Token with ARM Live service for downloading ground instrumentation via ACT.DISCOVERY\n",
    "# With your ARM username, you can find your ARM Live token here: https://adc.arm.gov/armlive/\n",
    "##ARM_USERNAME = os.getenv(\"ARM_USERNAME\")\n",
    "##ARM_TOKEN = os.getenv(\"ARM_TOKEN\")\n",
    "ARM_USERNAME = \"jrobrien\"\n",
    "ARM_TOKEN =  \"5c339110fc936ee3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30688245-b868-4ff5-ada3-a810fd7b2b82",
   "metadata": {},
   "source": [
    "## Define Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de2fe8a-22b6-403f-b21a-d476435de00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_points(nfile, **kwargs):\n",
    "    \"\"\"\n",
    "    Subset a radar file for a set of latitudes and longitudes\n",
    "    utilizing Py-ART's column-vertical-profile functionality.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        Path to the radar file to extract columns from\n",
    "    nsonde : list\n",
    "        List containing file paths to the desired sonde file to merge\n",
    "\n",
    "    Calls\n",
    "    -----\n",
    "    radar_start_time\n",
    "    merge_sonde\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ds : xarray DataSet\n",
    "        Xarray Dataset containing the radar column above a give set of locations\n",
    "    \n",
    "    \"\"\"\n",
    "    ds = None\n",
    "    \n",
    "    # Define the splash locations [lon,lat]\n",
    "    M1 = [34.34525, -87.33842]\n",
    "    S4 = [34.46451,\t-87.23598]\n",
    "    S20 = [34.65401, -87.29264]\n",
    "    S30\t= [34.38501, -86.92757]\n",
    "    S40\t= [34.17932, -87.45349]\n",
    "\n",
    "    sites = [\"M1\", \"S4\", \"S20\", \"S30\", \"S40\"]\n",
    "\n",
    "    # Zip these together!\n",
    "    lats, lons = list(zip(M1,\n",
    "                          S4,\n",
    "                          S20,\n",
    "                          S30,\n",
    "                          S40))\n",
    "    try:\n",
    "        # Read in the file\n",
    "        radar = pyart.io.read(nfile)\n",
    "        # Check for single sweep scans\n",
    "        if np.ma.is_masked(radar.sweep_start_ray_index[\"data\"][1:]):\n",
    "            radar.sweep_start_ray_index[\"data\"] = np.ma.array([0])\n",
    "            radar.sweep_end_ray_index[\"data\"] = np.ma.array([radar.nrays])\n",
    "    except:\n",
    "        radar = None\n",
    "\n",
    "    if radar:\n",
    "        if radar.scan_type != \"rhi\":\n",
    "            # Easier to map the nearest sonde file to radar gates before extraction\n",
    "            if 'sonde' in kwargs:\n",
    "                # variables to discard when reading in the sonde file\n",
    "                exclude_sonde = ['base_time', 'time_offset', 'lat', 'lon', 'qc_pres',\n",
    "                                 'qc_tdry', 'qc_dp', 'qc_wspd', 'qc_deg', 'qc_rh',\n",
    "                                 'qc_u_wind', 'qc_v_wind', 'qc_asc']\n",
    "        \n",
    "                # find the nearest sonde file to the radar start time\n",
    "                radar_start = datetime.datetime.strptime(nfile.split('/')[-1].split('.')[-3] + '.' + nfile.split('/')[-1].split('.')[-2], \n",
    "                                                         '%Y%m%d.%H%M%S'\n",
    "                )\n",
    "                sonde_start = [datetime.datetime.strptime(xfile.split('/')[-1].split('.')[2] + \n",
    "                                                          '-' + \n",
    "                                                          xfile.split('/')[-1].split('.')[3], \n",
    "                                                          '%Y%m%d-%H%M%S') for xfile in kwargs['sonde']\n",
    "                          ]\n",
    "                # difference in time between radar file and each sonde file\n",
    "                start_diff = [radar_start - sonde for sonde in sonde_start]\n",
    "\n",
    "                # merge the sonde file into the radar object\n",
    "                ds_sonde = act.io.read_arm_netcdf(kwargs['sonde'][start_diff.index(min(start_diff))], \n",
    "                                                  cleanup_qc=True, \n",
    "                                                  drop_variables=exclude_sonde)\n",
    "   \n",
    "                # create list of variables within sonde dataset to add to the radar file\n",
    "                for var in list(ds_sonde.keys()):\n",
    "                    if var != \"alt\":\n",
    "                        z_dict, sonde_dict = pyart.retrieve.map_profile_to_gates(ds_sonde.variables[var],\n",
    "                                                                                 ds_sonde.variables['alt'],\n",
    "                                                                                 radar)\n",
    "                    # add the field to the radar file\n",
    "                    radar.add_field_like('corrected_reflectivity', \"sonde_\" + var,  sonde_dict['data'], replace_existing=True)\n",
    "                    radar.fields[\"sonde_\" + var][\"units\"] = sonde_dict[\"units\"]\n",
    "                    radar.fields[\"sonde_\" + var][\"long_name\"] = sonde_dict[\"long_name\"]\n",
    "                    radar.fields[\"sonde_\" + var][\"standard_name\"] = sonde_dict[\"standard_name\"]\n",
    "                    radar.fields[\"sonde_\" + var][\"datastream\"] = ds_sonde.datastream\n",
    "\n",
    "                del radar_start, sonde_start, ds_sonde\n",
    "                del z_dict, sonde_dict\n",
    "        \n",
    "            column_list = []\n",
    "            for lat, lon in zip(lats, lons):\n",
    "                # Make sure we are interpolating from the radar's location above sea level\n",
    "                # NOTE: interpolating throughout Troposphere to match sonde to in the future\n",
    "                try:\n",
    "                    da = (\n",
    "                        pyart.util.columnsect.column_vertical_profile(radar, lat, lon)\n",
    "                        .interp(height=np.arange(radar.altitude['data'][0], 10050, 50))\n",
    "                    )\n",
    "                except ValueError:\n",
    "                    da = pyart.util.columnsect.column_vertical_profile(radar, lat, lon)\n",
    "                    \n",
    "                # Add the latitude and longitude of the extracted column\n",
    "                da[\"latitude\"], da[\"longitude\"] = lat, lon\n",
    "                # Time is based off the start of the radar volume\n",
    "                dt = pd.to_datetime(radar.time[\"data\"], unit='ms')[-1]\n",
    "                da[\"time\"] = [dt]\n",
    "                column_list.append(da)\n",
    "        \n",
    "            # Concatenate the extracted radar columns for this scan across all sites    \n",
    "            ds = xr.concat([data for data in column_list if data], dim='station')\n",
    "            ds[\"station\"] = sites\n",
    "            # Add attributes for Time, Latitude, Longitude, and Sites\n",
    "            ds.time.attrs.update(long_name=('Time in Seconds that Cooresponds to the Start'\n",
    "                                            + \" of each Individual Radar Volume Scan before\"\n",
    "                                            + \" Concatenation\"),\n",
    "                                 description=('Time in Seconds that Cooresponds to the Minimum'\n",
    "                                              + ' Height Gate'))\n",
    "            ds.station.attrs.update(long_name=\"Bankhead National Forest AMF-3 In-Situ Ground Observation Station Identifers\")\n",
    "            ds.latitude.attrs.update(long_name='Latitude of BNF AMF-3 Ground Observation Site',\n",
    "                                     units='Degrees North')\n",
    "            ds.longitude.attrs.update(long_name='Longitude of BNF AMF-3 Ground Observation Site',\n",
    "                                     units='Degrees East')\n",
    "            # delete the radar to free up memory\n",
    "            del radar, column_list, da\n",
    "        else:\n",
    "            # delete the rhi file\n",
    "            del radar\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0f9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_datasets_act(column, ground, site, discard, resample='sum', DataSet=False):\n",
    "    \"\"\"\n",
    "    Time synchronization of a Ground Instrumentation Dataset to \n",
    "    a Radar Column for Specific Locations using the ARM ACT package\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    column : Xarray DataSet\n",
    "        Xarray DataSet containing the extracted radar column above multiple locations.\n",
    "        Dimensions should include Time, Height, Site\n",
    "             \n",
    "    ground : str; Xarray DataSet\n",
    "        String containing the path of the ground instrumentation file that is desired\n",
    "        to be included within the extracted radar column dataset. \n",
    "        If DataSet is set to True, ground is Xarray Dataset and will skip I/O. \n",
    "             \n",
    "    site : str\n",
    "        Location of the ground instrument. Should be included within the filename. \n",
    "        \n",
    "    discard : list\n",
    "        List containing the desired input ground instrumentation variables to be \n",
    "        removed from the xarray DataSet. \n",
    "    \n",
    "    resample : str\n",
    "        Mathematical operational for resampling ground instrumentation to the radar time.\n",
    "        Default is to sum the data across the resampling period. Checks for 'mean' or \n",
    "        to 'skip' altogether. \n",
    "    \n",
    "    DataSet : boolean\n",
    "        Boolean flag to determine if ground input is an Xarray Dataset.\n",
    "        Set to True if ground input is Xarray DataSet. \n",
    "             \n",
    "    Returns\n",
    "    -------\n",
    "    ds : Xarray DataSet\n",
    "        Xarray Dataset containing the time-synced in-situ ground observations with\n",
    "        the inputed radar column \n",
    "    \"\"\"\n",
    "    # Check to see if input is xarray DataSet or a file path\n",
    "    if DataSet == True:\n",
    "        grd_ds = ground\n",
    "    else:\n",
    "        # Read in the file using ACT\n",
    "        grd_ds = act.io.read_arm_netcdf(ground, cleanup_qc=True, drop_variables=discard)\n",
    "        # Default are Lazy Arrays; convert for matching with column\n",
    "        grd_ds = grd_ds.compute()\n",
    "        # Check to see if file is the RWP, \n",
    "        if 'rwp' in ground[0].split('/')[-1]:\n",
    "            # adjust the RWP heights above ground level\n",
    "            grd_ds['height'] = grd_ds.height.data + grd_ds.alt.data\n",
    "        if 'ceil' in ground[0].split('/')[-1]:\n",
    "            # correct ceilometer backscatter \n",
    "            grd_ds = act.corrections.correct_ceil(grd_ds, var_name='backscatter')\n",
    "            # Rename the range dimension and apply altitude \n",
    "            grd_ds = grd_ds.rename({'range' : 'height'})\n",
    "            grd_ds['height'] = grd_ds.height.data + grd_ds.alt.data\n",
    "        \n",
    "    # Remove Base_Time before Resampling Data since you can't force 1 datapoint to 5 min sum\n",
    "    if 'base_time' in grd_ds.data_vars:\n",
    "        del grd_ds['base_time']\n",
    "        \n",
    "    # Check to see if height is a dimension within the ground instrumentation. \n",
    "    # If so, first interpolate heights to match radar, before interpolating time.\n",
    "    if 'height' in grd_ds.dims:\n",
    "        grd_ds = grd_ds.interp(height=np.arange(3150, 10050, 50), method='linear')\n",
    "        \n",
    "    # Resample the ground data to 5 min and interpolate to the CSU X-Band time. \n",
    "    # Keep data variable attributes to help distingish between instruments/locations\n",
    "    if resample.split('=')[-1] == 'mean':\n",
    "        matched = grd_ds.resample(time='5Min', \n",
    "                                  closed='right').mean(keep_attrs=True).interp(time=column.time, \n",
    "                                                                               method='linear')\n",
    "    elif resample.split('=')[-1] == 'skip':\n",
    "        matched = grd_ds.interp(time=column.time, method='linear')\n",
    "    else:\n",
    "        matched = grd_ds.resample(time='5Min', \n",
    "                                  closed='right').sum(keep_attrs=True).interp(time=column.time, \n",
    "                                                                              method='linear')\n",
    "    \n",
    "    # Add SAIL site location as a dimension for the Pluvio data\n",
    "    matched = matched.assign_coords(coords=dict(site=site))\n",
    "    matched = matched.expand_dims('site')\n",
    "   \n",
    "    # Remove Lat/Lon Data variables as it is included within the Matched Dataset with Site Identfiers\n",
    "    if 'lat' in matched.data_vars:\n",
    "        del matched['lat']\n",
    "    if 'lon' in matched.data_vars:\n",
    "        del matched['lon']\n",
    "    if 'alt' in matched.data_vars:\n",
    "        del matched['alt']\n",
    "        \n",
    "    # Update the individual Variables to Hold Global Attributes\n",
    "    # global attributes will be lost on merging into the matched dataset.\n",
    "    # Need to keep as many references and descriptors as possible\n",
    "    for var in matched.data_vars:\n",
    "        matched[var].attrs.update(source=matched.datastream)\n",
    "        \n",
    "    # Merge the two DataSets\n",
    "    column = xr.merge([column, matched])\n",
    "   \n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2ec20-bb15-441a-b726-38f29cf63752",
   "metadata": {},
   "source": [
    "## Find / Download In-Situ Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff5dd04a-3c4d-44b1-8879-fddfd29b4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the datastream and output directory\n",
    "insitu_stream = {'bnfmetM1.b1' : INSITU_DIR + 'bnfmetM1.b1',\n",
    "                 'bnfmetS20.b1' : INSITU_DIR + \"bnfmetS20.b1\",\n",
    "                 \"bnfmetS30.b1\" : INSITU_DIR + \"bnfmetS30.b1\",\n",
    "                 \"bnfmetS40.b1\" : INSITU_DIR + \"bnfmetS40.b1\",\n",
    "                 \"bnfsondewnpnM1.b1\" : INSITU_DIR + \"bnfsondewnpnM1.b1\",\n",
    "                 \"bnfwbpluvio2M1.a1\" : INSITU_DIR + \"bnfwbpluvio2M1.a1\",\n",
    "                 \"bnfldquantsM1.c1\" : INSITU_DIR + \"bnfldquantsM1.c1\",\n",
    "                 \"bnfldquantsS30.c1\" : INSITU_DIR + \"bnfldquantsS30.c1\",\n",
    "                 \"bnfvdisquantsM1.c1\" : INSITU_DIR + \"bnfvdisquantsM1.c1\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "651b797f-f7de-481f-a8f4-ddfef9a455b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfmetM1.b1\n",
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfmetS20.b1\n",
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfmetS30.b1\n",
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfmetS40.b1\n",
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfsondewnpnM1.b1\n",
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfwbpluvio2M1.a1\n",
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfldquantsM1.c1\n",
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfldquantsS30.c1\n",
      "/nfs/gce/globalscratch/obrienj/bnf-cmac-r2/in_situ/bnfvdisquantsM1.c1\n"
     ]
    }
   ],
   "source": [
    "for var in insitu_stream:\n",
    "    print(insitu_stream[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc35db1-9ef4-4838-8f81-2b93d798540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOWNLOADING] bnfmetM1.b1.20250109.000000.cdf\n",
      "\n",
      "If you use these data to prepare a publication, please cite:\n",
      "\n",
      "Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
      "(MET), 2025-01-09 to 2025-01-09, Bankhead National Forest, AL, USA; Long-term\n",
      "Mobile Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) (M1).\n",
      "Atmospheric Radiation Measurement (ARM) User Facility.\n",
      "https://doi.org/10.5439/1786358\n",
      "\n",
      "[DOWNLOADING] bnfmetS20.b1.20250109.000000.cdf\n",
      "\n",
      "If you use these data to prepare a publication, please cite:\n",
      "\n",
      "Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
      "(MET), 2025-01-09 to 2025-01-09, Bankhead National Forest, AL, USA; Long-term\n",
      "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
      "Courtland (S20). Atmospheric Radiation Measurement (ARM) User Facility.\n",
      "https://doi.org/10.5439/1786358\n",
      "\n",
      "[DOWNLOADING] bnfmetS30.b1.20250109.000000.cdf\n",
      "\n",
      "If you use these data to prepare a publication, please cite:\n",
      "\n",
      "Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
      "(MET), 2025-01-09 to 2025-01-09, Bankhead National Forest, AL, USA; Long-term\n",
      "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
      "Falkville (S30). Atmospheric Radiation Measurement (ARM) User Facility.\n",
      "https://doi.org/10.5439/1786358\n",
      "\n",
      "[DOWNLOADING] bnfmetS40.b1.20250109.000000.cdf\n",
      "\n",
      "If you use these data to prepare a publication, please cite:\n",
      "\n",
      "Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
      "(MET), 2025-01-09 to 2025-01-09, Bankhead National Forest, AL, USA; Long-term\n",
      "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
      "Double Springs (S40). Atmospheric Radiation Measurement (ARM) User Facility.\n",
      "https://doi.org/10.5439/1786358\n",
      "\n",
      "[DOWNLOADING] bnfsondewnpnM1.b1.20250109.173000.cdf\n",
      "[DOWNLOADING] bnfsondewnpnM1.b1.20250109.053000.cdf\n",
      "[DOWNLOADING] bnfsondewnpnM1.b1.20250109.113000.cdf\n",
      "[DOWNLOADING] bnfsondewnpnM1.b1.20250109.233000.cdf\n",
      "\n",
      "If you use these data to prepare a publication, please cite:\n",
      "\n",
      "Keeler, E., Burk, K., & Kyrouac, J. Balloon-Borne Sounding System (SONDEWNPN),\n",
      "2025-01-09 to 2025-01-09, Bankhead National Forest, AL, USA; Long-term Mobile\n",
      "Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) (M1). Atmospheric\n",
      "Radiation Measurement (ARM) User Facility. https://doi.org/10.5439/1595321\n",
      "\n",
      "[DOWNLOADING] bnfwbpluvio2M1.a1.20250109.000000.nc\n",
      "\n",
      "If you use these data to prepare a publication, please cite:\n",
      "\n",
      "Zhu, Z., Wang, D., Jane, M., Cromwell, E., Sturm, M., Irving, K., & Delamere, J.\n",
      "Weighing Bucket Precipitation Gauge (WBPLUVIO2), 2025-01-09 to 2025-01-09,\n",
      "Bankhead National Forest, AL, USA; Long-term Mobile Facility (BNF), Bankhead\n",
      "National Forest, AL, AMF3 (Main Site) (M1). Atmospheric Radiation Measurement\n",
      "(ARM) User Facility. https://doi.org/10.5439/1338194\n",
      "\n",
      "[DOWNLOADING] bnfldquantsM1.c1.20250109.142900.nc\n",
      "\n",
      "If you use these data to prepare a publication, please cite:\n",
      "\n",
      "Hardin, J., Giangrande, S., & Zhou, A. Laser Disdrometer Quantities (LDQUANTS),\n",
      "2025-01-09 to 2025-01-09, Bankhead National Forest, AL, USA; Long-term Mobile\n",
      "Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) (M1). Atmospheric\n",
      "Radiation Measurement (ARM) User Facility. https://doi.org/10.5439/1432694\n",
      "\n",
      "[DOWNLOADING] bnfldquantsS30.c1.20250109.000000.nc\n",
      "\n",
      "If you use these data to prepare a publication, please cite:\n",
      "\n",
      "Hardin, J., Giangrande, S., & Zhou, A. Laser Disdrometer Quantities (LDQUANTS),\n",
      "2025-01-09 to 2025-01-09, Bankhead National Forest, AL, USA; Long-term Mobile\n",
      "Facility (BNF), Bankhead National Forest, AL, Supplemental facility at Falkville\n",
      "(S30). Atmospheric Radiation Measurement (ARM) User Facility.\n",
      "https://doi.org/10.5439/1432694\n",
      "\n",
      "No files returned or url status error.\n",
      "Check datastream name, start, and end date.\n"
     ]
    }
   ],
   "source": [
    "# We can use the ACT module for downloading data from the ARM web service\n",
    "for insitu in insitu_stream:\n",
    "    #if insitu != \"bnfsondewnpnM1.b1\":\n",
    "        results = act.discovery.download_arm_data(ARM_USERNAME, \n",
    "                                                  ARM_TOKEN, \n",
    "                                                  insitu, \n",
    "                                                  DATE, \n",
    "                                                  DATE, \n",
    "                                                  output=insitu_stream[insitu])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00789bb-406b-4edf-b2f2-d03e58166e3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Locate the CMAC Processed CSAPR-2 and Radiosonde Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd81b915-b600-4b18-ab78-37a63de18b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.000253.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.000311.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.001255.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.001313.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.002258.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.002316.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.003301.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.003319.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.004303.nc',\n",
       " '/nfs/gce/globalscratch/obrienj/bnf-cmac/bnfcsapr2cmacS3.c1.20250305.004321.nc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the user defined RADAR_DIR, grab all the XPRECIPRADAR CMAC files for the defined DATE\n",
    "file_list = sorted(glob.glob(RADAR_DIR + 'bnfcsapr2cmacS3.c1.' + DATE.replace('-', '') + '*.nc'))\n",
    "file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9c5b52-5e32-4d0f-81fb-91fe8a341714",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsonde = sorted(glob.glob(insitu_stream[\"bnfsondewnpnM1.b1\"] + '/*' + DATE.replace('-', '') + '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f78763f9-c320-469b-aed1-a4b50477a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n",
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n",
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n",
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 16:18:59,228 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 32.84 GiB -- Worker memory limit: 46.89 GiB\n",
      "2025-03-21 16:19:17,333 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       subset_points-a8e4fafeec0306fe9eb1aa03addfe221\n",
      "State:     long-running\n",
      "Task:  <Task 'subset_points-a8e4fafeec0306fe9eb1aa03addfe221' subset_points(..., ...)>\n",
      "Exception: 'ValueError(\"conflicting sizes for dimension \\'station\\': length 5 on \\'station\\' and length 1 on {\\'station\\': \\'attenuation_corrected_differential_reflectivity\\', \\'height\\': \\'attenuation_corrected_differential_reflectivity\\', \\'time\\': \\'time\\'}\")'\n",
      "Traceback: '  File \"/tmp/ipykernel_1708717/427212614.py\", line 115, in subset_points\\n  File \"/home/obrienj/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/core/dataset.py\", line 1372, in __setitem__\\n    self.update({key: value})\\n  File \"/home/obrienj/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/core/dataset.py\", line 5566, in update\\n    merge_result = dataset_update_method(self, other)\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/obrienj/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/structure/merge.py\", line 1056, in dataset_update_method\\n    return merge_core(\\n           ^^^^^^^^^^^\\n  File \"/home/obrienj/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/structure/merge.py\", line 706, in merge_core\\n    dims = calculate_dimensions(variables)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/obrienj/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/core/variable.py\", line 3022, in calculate_dimensions\\n    raise ValueError(\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "conflicting sizes for dimension 'station': length 5 on 'station' and length 1 on {'station': 'attenuation_corrected_differential_reflectivity', 'height': 'attenuation_corrected_differential_reflectivity', 'time': 'time'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:5\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/distributed/client.py:2565\u001b[39m, in \u001b[36mClient.gather\u001b[39m\u001b[34m(self, futures, errors, direct, asynchronous)\u001b[39m\n\u001b[32m   2562\u001b[39m     local_worker = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2564\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdirect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m        \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m=\u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36msubset_points\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Concatenate the extracted radar columns for this scan across all sites    \u001b[39;00m\n\u001b[32m    114\u001b[39m ds = xr.concat([data \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m column_list \u001b[38;5;28;01mif\u001b[39;00m data], dim=\u001b[33m'\u001b[39m\u001b[33mstation\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m ds[\u001b[33m\"\u001b[39m\u001b[33mstation\u001b[39m\u001b[33m\"\u001b[39m] = sites\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Add attributes for Time, Latitude, Longitude, and Sites\u001b[39;00m\n\u001b[32m    117\u001b[39m ds.time.attrs.update(long_name=(\u001b[33m'\u001b[39m\u001b[33mTime in Seconds that Cooresponds to the Start\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    118\u001b[39m                                 + \u001b[33m\"\u001b[39m\u001b[33m of each Individual Radar Volume Scan before\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m                                 + \u001b[33m\"\u001b[39m\u001b[33m Concatenation\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    120\u001b[39m                      description=(\u001b[33m'\u001b[39m\u001b[33mTime in Seconds that Cooresponds to the Minimum\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    121\u001b[39m                                   + \u001b[33m'\u001b[39m\u001b[33m Height Gate\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/core/dataset.py:1372\u001b[39m, in \u001b[36m__setitem__\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1367\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Dataset):\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   1369\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot assign a Dataset to a single key - only a DataArray or Variable \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1370\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mobject can be stored under a single key.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1371\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28mself\u001b[39m.update({key: value})\n\u001b[32m   1374\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m utils.iterable_of_hashable(key):\n\u001b[32m   1375\u001b[39m     keylist = \u001b[38;5;28mlist\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/core/dataset.py:5566\u001b[39m, in \u001b[36mupdate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   5530\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: CoercibleMapping) -> Self:\n\u001b[32m   5531\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update this dataset's variables with those from another dataset.\u001b[39;00m\n\u001b[32m   5532\u001b[39m \n\u001b[32m   5533\u001b[39m \u001b[33;03m    Just like :py:meth:`dict.update` this is a in-place operation.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5564\u001b[39m \u001b[33;03m    Dataset.merge\u001b[39;00m\n\u001b[32m   5565\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5566\u001b[39m     merge_result = dataset_update_method(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m   5567\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._replace(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, **merge_result._asdict())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/structure/merge.py:1056\u001b[39m, in \u001b[36mdataset_update_method\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1053\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m coord_names:\n\u001b[32m   1054\u001b[39m                 other[key] = value.drop_vars(coord_names)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m merge_core(\n\u001b[32m   1057\u001b[39m     [dataset, other],\n\u001b[32m   1058\u001b[39m     priority_arg=\u001b[32m1\u001b[39m,\n\u001b[32m   1059\u001b[39m     indexes=dataset.xindexes,\n\u001b[32m   1060\u001b[39m     combine_attrs=\u001b[33m\"\u001b[39m\u001b[33moverride\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1061\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/structure/merge.py:706\u001b[39m, in \u001b[36mmerge_core\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    701\u001b[39m prioritized = _get_priority_vars_and_indexes(aligned, priority_arg, compat=compat)\n\u001b[32m    702\u001b[39m variables, out_indexes = merge_collected(\n\u001b[32m    703\u001b[39m     collected, prioritized, compat=compat, combine_attrs=combine_attrs\n\u001b[32m    704\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m dims = calculate_dimensions(variables)\n\u001b[32m    708\u001b[39m coord_names, noncoord_names = determine_coords(coerced)\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compat == \u001b[33m\"\u001b[39m\u001b[33mminimal\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    710\u001b[39m     \u001b[38;5;66;03m# coordinates may be dropped in merged results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/amf3-radar-examples-dev/lib/python3.11/site-packages/xarray/core/variable.py:3022\u001b[39m, in \u001b[36mcalculate_dimensions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   3020\u001b[39m             last_used[dim] = k\n\u001b[32m   3021\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m dims[dim] != size:\n\u001b[32m-> \u001b[39m\u001b[32m3022\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3023\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconflicting sizes for dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3024\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m and length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdims[dim]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_used\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   3025\u001b[39m             )\n\u001b[32m   3026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dims\n",
      "\u001b[31mValueError\u001b[39m: conflicting sizes for dimension 'station': length 5 on 'station' and length 1 on {'station': 'attenuation_corrected_differential_reflectivity', 'height': 'attenuation_corrected_differential_reflectivity', 'time': 'time'}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Start up a Dask Cluster\n",
    "cluster = LocalCluster(n_workers=4)\n",
    "with Client(cluster) as client:\n",
    "    future = client.map(subset_points, file_list[:60], sonde=nsonde)\n",
    "    my_data = client.gather(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01f504b-cb54-4e10-9556-b8a16a393f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%time\n",
    "##my_data = []\n",
    "##j = 0\n",
    "##for i in range(10, len(file_list), 10):\n",
    "##    print(j, i)\n",
    "##    iter_list = []\n",
    "##    for scan in file_list[j:i]:\n",
    "##        print(scan)\n",
    "##        iter_list.append(subset_points(scan, sonde=nsonde))\n",
    "##    print(len(iter_list))\n",
    "##    if len(iter_list) > 0:\n",
    "##        my_data.append(xr.concat([data for data in iter_list if data], dim='time'))\n",
    "##    j += 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3695f",
   "metadata": {},
   "source": [
    "## Combine all Extracted Radar Columns to Form Daily Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43aae040",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Concatenate all extracted columns across time dimension to form daily timeseries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ds = xr.concat([data \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmy_data\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m data], dim=\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'my_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Concatenate all extracted columns across time dimension to form daily timeseries\n",
    "ds = xr.concat([data for data in my_data if data], dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf06b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd98940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f314579",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.drop_vars(\"base_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632db6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf('bnf-radclss-test.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63b93a",
   "metadata": {},
   "source": [
    "## Read in the temporary saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9771c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rad = xr.open_dataset(file_list[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94768676",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36657f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rad.altitude.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bda0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new = xr.open_dataset('bnf-radclss-test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b459a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new.height.data[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Global Attributes from the Column Extraction\n",
    "# Attributes make sense for single location, but not collection of sites. \n",
    "ds.attrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Base_Time variable from extracted column\n",
    "del ds['base_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea866a",
   "metadata": {},
   "source": [
    "## Define Dictionary of Variables to Remove from Each Datastream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572534fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_var = {'LD' : ['base_time', 'time_offset', 'equivalent_radar_reflectivity_ott',\n",
    "                       'laserband_amplitude', 'sensor_temperature', 'heating_current', 'sensor_voltage', \n",
    "                       'moment1', 'moment2', 'moment3', 'moment4',\n",
    "                       'moment5', 'moment6', 'lat', 'lon', 'alt',\n",
    "                       'qc_precip_rate', 'qc_weather_code', 'qc_equivalent_radar_reflectivity_ott',\n",
    "                       'qc_number_detected_particles', 'qc_mor_visibility', 'qc_snow_depth_intensity',\n",
    "                       'qc_laserband_amplitude', 'qc_heating_current', 'qc_sensor_voltage'\n",
    "                      ],\n",
    "               'Pluvio' : ['base_time', 'time_offset', 'load_cell_temp', 'heater_status',\n",
    "                          'elec_unit_temp', 'supply_volts', 'orifice_temp', 'volt_min',\n",
    "                          'ptemp', 'lat', 'lon', 'alt', 'maintenance_flag', 'reset_flag', \n",
    "                          'qc_rh_mean', 'pluvio_status'\n",
    "                          ],\n",
    "               'Met' : ['base_time', 'time_offset', 'time_bounds', 'logger_volt',\n",
    "                        'logger_temp', 'qc_logger_temp', 'lat', 'lon', 'alt', 'qc_temp_mean',\n",
    "                        'qc_rh_mean', 'qc_vapor_pressure_mean', 'qc_wspd_arith_mean', 'qc_wspd_vec_mean',\n",
    "                        'qc_wdir_vec_mean', 'qc_pwd_mean_vis_1min', 'qc_pwd_mean_vis_10min', 'qc_pwd_pw_code_inst',\n",
    "                        'qc_pwd_pw_code_15min', 'qc_pwd_pw_code_1hr', 'qc_pwd_precip_rate_mean_1min',\n",
    "                        'qc_pwd_cumul_rain', 'qc_pwd_cumul_snow', 'qc_org_precip_rate_mean', 'qc_tbrg_precip_total',\n",
    "                        'qc_tbrg_precip_total_corr', 'qc_logger_volt', 'qc_logger_temp', 'qc_atmos_pressure', \n",
    "                        'pwd_pw_code_inst', 'pwd_pw_code_15min', 'pwd_pw_code_1hr', \n",
    "                       ],\n",
    "               'RWP' : ['base_time', 'time_offset', 'time_bounds', 'height_bounds', 'vertical_wind_speed_count',\n",
    "                        'vertical_wind_speed_quality_flag', 'lat', 'lon'\n",
    "                       ],\n",
    "               'ceil': ['base_time', 'time_offset', 'time_bounds', 'range_bounds', 'detection_status',\n",
    "                        'status_flag', 'qc_first_cbh', 'qc_vertical_visibility', 'qc_second_cbh', 'qc_alt_highest_signal', \n",
    "                        'qc_third_cbh', 'laser_pulse_energy', 'qc_laser_pulse_energy', 'laser_temperature', 'qc_laser_temperature',\n",
    "                        'window_transmission', 'qc_window_transmission', 'tilt_angle', 'qc_tilt_angle', 'background_light',\n",
    "                        'qc_background_light', 'sum_backscatter', 'qc_sum_backscatter', 'measurement_parameters', 'status_string',\n",
    "                        'alt_highest_signal', 'lat', 'lon'\n",
    "                       ]\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f5afd",
   "metadata": {},
   "source": [
    "## Save the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a filename\n",
    "out_ds.to_netcdf('xprecipradarradclss.c2.' + DATE.replace('-', '') + '.000000.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558096c3-19e2-4a1e-9452-08bb6e911277",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Surface Meteorological Instrumentation (MET)\n",
    "- Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
    "(MET), 2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term\n",
    "Mobile Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) **(M1)**.\n",
    "Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1786358\n",
    "\n",
    "- Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
    "(MET), 2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term\n",
    "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
    "Courtland **(S20)**. Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1786358\n",
    "\n",
    "- Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
    "(MET), 2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term\n",
    "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
    "Falkville **(S30)**. Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1786358\n",
    "\n",
    "- Kyrouac, J., Shi, Y., & Tuftedal, M. Surface Meteorological Instrumentation\n",
    "(MET), 2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term\n",
    "Mobile Facility (BNF), Bankhead National Forest, AL, Supplemental facility at\n",
    "Double Springs **(S40)**. Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1786358\n",
    "\n",
    "### Balloon-Borne Sounding System (SONDEWNPN)\n",
    "- Keeler, E., Burk, K., & Kyrouac, J. Balloon-Borne Sounding System (SONDEWNPN),\n",
    "2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term Mobile\n",
    "Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) **(M1)**. Atmospheric\n",
    "Radiation Measurement (ARM) User Facility. https://doi.org/10.5439/1595321\n",
    "\n",
    "### Weighing Bucket Preciptiation Gauge (WBPLUVIO2)\n",
    "- Zhu, Z., Wang, D., Jane, M., Cromwell, E., Sturm, M., Irving, K., & Delamere, J.\n",
    "Weighing Bucket Precipitation Gauge (WBPLUVIO2), 2025-03-05 to 2025-03-05,\n",
    "Bankhead National Forest, AL, USA; Long-term Mobile Facility (BNF), Bankhead\n",
    "National Forest, AL, AMF3 (Main Site) **(M1)**. Atmospheric Radiation Measurement\n",
    "(ARM) User Facility. https://doi.org/10.5439/1338194\n",
    "\n",
    "### Laser Disdrometer Quantities (LDQUANTS)\n",
    "- Hardin, J., Giangrande, S., & Zhou, A. Laser Disdrometer Quantities (LDQUANTS),\n",
    "2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term Mobile\n",
    "Facility (BNF), Bankhead National Forest, AL, AMF3 (Main Site) **(M1)**. Atmospheric\n",
    "Radiation Measurement (ARM) User Facility. https://doi.org/10.5439/1432694\n",
    "\n",
    "- Hardin, J., Giangrande, S., & Zhou, A. Laser Disdrometer Quantities (LDQUANTS),\n",
    "2025-03-05 to 2025-03-05, Bankhead National Forest, AL, USA; Long-term Mobile\n",
    "Facility (BNF), Bankhead National Forest, AL, Supplemental facility at Falkville\n",
    "**(S30)**. Atmospheric Radiation Measurement (ARM) User Facility.\n",
    "https://doi.org/10.5439/1432694\n",
    "\n",
    "### Video Disdrometer Quantities (VDISQUANTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f873d74-9e73-43a2-abe0-e7a6dd20e5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amf3-radar-examples-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
